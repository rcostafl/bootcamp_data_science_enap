{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aula 3 - Pandas e Fontes de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulação de Fontes de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazer o download dos datasets\n",
    "!git clone https://github.com/alexlopespereira/curso_ciencia_dados2020.git ../../curso_ciencia_dados2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregar dados de um Arquivo XLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ler o arquivo com o pib dos municípios brasileiros e guarde numa variável df_pib\n",
    "\n",
    "\n",
    "# sheet_name é o argumento para o aba da planilha desejada. \n",
    "# Se você quiser a 1a aba, não precisa especificar.\n",
    "# .. significa o diretorio pai do diretorio atual. Se quiser saber o diretorio atual\n",
    "# use o seguinte código\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra os primeiros 4 registros da variavel df_pib\n",
    "df_pib.head(4)\n",
    "### As 3 primeiras e a ultima linha são inuteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra os ultimos 4 registros da variavel df_pib\n",
    "df_pib.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o arquivo do pib removendo as 3 primeiras linhas e a última\n",
    "\n",
    "\n",
    "# Mostra os primeiros registros\n",
    "df_pib.head()\n",
    "# O nome das 3 primeiras colunas está incoerente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear estas colunas\n",
    "\n",
    "\n",
    "# Mostra os primeiros registros\n",
    "df_pib.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregar dados de um Arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar este dataframe em formato CSV\n",
    "# O separador padrão é vírgula. Use o ; para testar a especificação de um separador\n",
    "# Recomendação para nomes de arquivos: use nomes simples, sem espaço e sem caracteres especiais.\n",
    "\n",
    "\n",
    "# Para mostrar as primeiras linhas do arquivo no Linux: !head ../data/pib_municipios.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregue o arquivo pib_municipios.csv. Atente para o separador correto.\n",
    "\n",
    "\n",
    "# Mostra os primeiros registros\n",
    "df_pib_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregar dados de uma API REST e Arquivo JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler um arquivo JSON de uma URL para um dataframe df_dolar. \n",
    "# Pode-se carregar de uma pasta local também.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra os primeiros registros deste dataframe df_dolar\n",
    "df_dolar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste a conversão para DataFrame a partir de um JSON mais complexo \n",
    "# Carregue o dataframe retornado pela chamada \n",
    "#   GET à URL \"https://www.servicos.gov.br/api/v1/servicos/9029\"\n",
    "\n",
    "\n",
    "# Mostra os primeiros registros\n",
    "df_servicos.head()\n",
    "# O resultado não foi como esperado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A função read_json não conseguiu processar e criar o DataFrame esperado a partir do JSON\n",
    "#### A solução alternativa é selecionar os atributos do JSON e colocar num dicionário para construir um DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # Biblioteca que realiza requisições HTTP em python\n",
    "\n",
    "def get_servicos(siorg):\n",
    "    '''Retorna os dados da API de serviços para o órgao especificado pelo argumento siorg\n",
    "    '''\n",
    "    url = 'https://servicos.gov.br/api/v1/servicos/orgao/{0}'.format(siorg)\n",
    "    response = requests.get(url) # Realiza uma requisição http\n",
    "    input_json = response.json()\n",
    "    if not input_json or 'resposta' not in input_json:\n",
    "        print(\"Os dados da api de servicos nao estao disponiveis\")\n",
    "        return {}\n",
    "    input_json = input_json['resposta']\n",
    "    result = []\n",
    "    for i in input_json: # iteração para cada serviço do órgão\n",
    "        servico_id = i['id'].split('/')[6]\n",
    "        servico_nome = i['nome']\n",
    "        servico_url = i['url'][36:]\n",
    "        orgao_id = i['orgao']['id'].split('/')[5]\n",
    "        orgao_dbId = i['orgao']['dbId']\n",
    "        orgao_nome = i['orgao']['nomeOrgao']\n",
    "        result.append({'servico_id': servico_id, 'servico_nome': servico_nome, 'servico_url': servico_url, 'orgao_nome': orgao_nome,\n",
    "                              'orgao_id': orgao_id, 'orgao_dbId': orgao_dbId})\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa o método com o sirgo da Fio Cruz\n",
    "d = get_servicos(315) \n",
    "# Transforma a lista de dicionários num DataFrame\n",
    "\n",
    "# Mostra os primeiros registros\n",
    "df_servicos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregar dados de Arquivo HTML (Web Scrapy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler um arquivo HTML (https://en.wikipedia.org/wiki/Pythonidae) \n",
    "#   carregando as tabelas presentes (Web Scrapy)\n",
    "\n",
    "\n",
    "# Mostra os primeiros registros da tabela 2 da página analisada\n",
    "df_python[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear as colunas do dataframe retirando colchetes e espaço, usando\n",
    "#     um mapeamento 'antes':'depois' no formato de um dicionário.\n",
    "# Use inplace=True\n",
    "\n",
    "\n",
    "# Mostra os primeiros registros da tabela 2\n",
    "df_python[2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados em Bancos de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converter um dataframe para uma tabela de banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O banco de dados SQLite é um banco bem simples gerenciado em um único arquivo. \n",
    "# É usado, por exemplo, em aplicativos de celular.\n",
    "# A biblioteca sqlalchemy é um mapeamento objeto-relacional para vários SGBDs.\n",
    "# Esta biblioteca consegue executar comandos SQL em todos os SGBDs compatíveis.\n",
    "import sqlalchemy as sqla\n",
    "\n",
    "# Crie uma conexão com o banco de dados\n",
    "con = sqla.create_engine('sqlite:///../data/curso_cd.sqlite')\n",
    "\n",
    "# Escreva o DataFrame df_python[2] numa tabela de um banco de dados SQLite\n",
    "df_python[2].to_sql(\"python\", con, if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Você pode visualizar seu banco de dados de forma independente \n",
    "#### em https://inloop.github.io/sqlite-viewer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carregar os dados de uma tabela de banco de dados para um DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute uma query SELECT no banco de dados sqlite convertendo toda a tabela python num DataFrame\n",
    "# ajustando o parametro index_col='index'\n",
    "\n",
    "# Visualize os primeiros registros\n",
    "df_sqlite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fazer cálculos envolvendo agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a soma quantidade de subespecies de cada especie\n",
    "\n",
    "\n",
    "# Mostra os primeiros registros da agregação\n",
    "df_sqlite_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a quantidade de subspecies de cada região geográfica e ordenar pela \n",
    "# quantidade de subspecies de forma decrescente\n",
    "\n",
    "\n",
    "# Mostra os primeiros 10 registros da agregação\n",
    "df_sqlite_agg2.head(10)\n",
    "\n",
    "# Fecha a conexão com o banco de dados\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras Operacoes no Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descartando valores faltantes (NA ou NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan as NA\n",
    "# Considere a serie a seguir\n",
    "data = pd.Series([1, NA, 3.5, NA, 7])\n",
    "# Remova os valores NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando equivalente ao dropna, mas usando o método notnull()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preenchendo valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere o seguinte DataFrame\n",
    "# Construir um dataframe a partir de uma matriz de 7 x 3 de números aleatórios \n",
    "# de uma distribuição normal padrão\n",
    "df = pd.DataFrame(np.random.randn(7, 3)) \n",
    "# Preencha o DataFrame com alguns valores NA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencha os valores NA com zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use um mapeamento (com dicionário) para preencher os valores NA\n",
    "# Na coluna 1 substitua NA por 0.5 e na coluna 2 substitua NA por 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencha com zero alterando o DataFrame df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere o seguinte dataframe\n",
    "df = pd.DataFrame(np.random.randn(7, 3)) \n",
    "# Preencha o DataFrame com alguns valores NA\n",
    "df.iloc[1:4, 1] = NA\n",
    "df.iloc[1:3, 2] = NA\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencha os valores NA com o método ffill \n",
    "df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remover duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere o seguinte dataframe\n",
    "data = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'], 'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostre quais desses itens são duplicados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remova os itens duplicados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexação Hierárquica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possibilita mais de um nível de indexação num eixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere a seguinte Serie\n",
    "data = pd.Series(np.random.randn(9), index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n",
    "                                            [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
    "# Mostre o indice hierárquico\n",
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça um filtro com uma lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça um filtro no 2o Nível (mais interno)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere o seguinte dataframe\n",
    "frame = pd.DataFrame(np.arange(12).reshape((4, 3)),\n",
    "                     index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                     columns=[['Ohio', 'Ohio', 'Colorado'],['Green', 'Red', 'Green']])\n",
    "frame.index.names = ['key1', 'key2']\n",
    "frame.columns.names = ['state', 'color']\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo estatístico por nível\n",
    "# Extraia a soma da agregação do nível 2 (mais interno)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge (fundir/juntar)\n",
    "#### A chave de junção (identificador único) foi inferida a partir do contexto (procurando nas colunas)\n",
    "#### Também pode ser especificada com o argumento on (Ex.: on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere os seguintes DataFrames\n",
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)})\n",
    "df2 = pd.DataFrame({'key': ['a', 'b', 'd'], 'data2': range(3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostre o dataframe df1\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostre o dataframe df2\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça o merge dos dois dataframes usando como chave de junção a coluna 'key'\n",
    "\n",
    "\n",
    "# Por que chamamos esse tipo de merge/join de inner ? R.: Porque ele considera apenas a \n",
    "#     intersecção dos dois conjuntos de chaves.\n",
    "# O argumento how='inner' é o padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça também o merge com o argumento how='outer'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join (fundir/juntar)\n",
    "#### Semelhante ao merge, mas a chave de junção é o índice do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere os seguintes DataFrames\n",
    "left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]], index=['a', 'c', 'e'], \n",
    "                     columns=['Ohio', 'Nevada'])\n",
    "right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],index=['b', 'c', 'd', 'e'],\n",
    "                     columns=['Missouri', 'Alabama'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostre o dataframe left2\n",
    "left2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostre o dataframe right2\n",
    "right2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça o join entre os dois DataFrames sem descartar registros que não estejam \n",
    "#      nos dois DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considerando os dataframes left2 e right2 definidos acima\n",
    "# Faça o join entre os dois DataFrames sem descartar registros que estejam \n",
    "# apenas no dataframe left2, e descartando registros que estejam apenas no right2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping / Pivoting (Pivotar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere o seguinte DataFrame\n",
    "table = {\n",
    "    'Aluno': ['AlunoA', 'AlunoA', 'AlunoA', 'AlunoA', 'AlunoB', 'AlunoB', 'AlunoB', 'AlunoB'],\n",
    "    'Disciplina': ['Portugues', 'Matematica', 'Geografia', 'História', 'Portugues', 'Matematica', 'Geografia', 'História'],\n",
    "    'Objetiva': [8.5, 7.5, 9, 10, 8.5, 7.5, 9, 10],\n",
    "    'Discursiva': [6, 6.5, 7.5, 7, 8.5, 7.5, 9, 10]}\n",
    "df_provas = pd.DataFrame(table)\n",
    "df_provas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivote o dataframe df_provas colocando a coluna Aluno como índice, \n",
    "# os valores da coluna Disciplina como colunas, e os valores da coluna Objetiva\n",
    "# como conteúdo do novo dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E quando houver valores repetidos ?\n",
    "#### Pivotar com o mesmo método pivot() gera exceção. Neste caso, use o método pivot_table \n",
    "#### mean é a métrica padrão de cálculo sobre a de agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere o seguinte DataFrame\n",
    "table2 = {\n",
    "    'Aluno': ['AlunoA', 'AlunoA', 'AlunoA', 'AlunoA', 'AlunoA', 'AlunoB', 'AlunoB', 'AlunoB', 'AlunoB'],\n",
    "    'Disciplina': ['Portugues', 'Matematica', 'Geografia', 'Geografia', 'História', 'Portugues', 'Matematica', 'Geografia', 'História'],\n",
    "    'Objetiva': [8.5, 7.5, 9, 10, 9, 8.5, 7.5, 9, 10],\n",
    "    'Discursiva': [6, 6.5, 7.5, 7, 8, 8.5, 7.5, 9, 10]}\n",
    "df_provas2 = pd.DataFrame(table2)\n",
    "df_provas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivotar com o mesmo comando gera uma exceção\n",
    "# df_pivoted2 = df_provas2.pivot(index='Aluno', columns='Disciplina', values='Objetiva')\n",
    "# Use a funcao pivot_table. O valor padrão do argumento aggfunc é 'mean'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping / Pivoting com Índice Hierárquico\n",
    "#### Método stack/unstack (Pivotar com índice hierárquico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considere o seguinte dataframe\n",
    "data = pd.DataFrame(np.arange(6).reshape((2, 3)),\n",
    "                    index=pd.Index(['Ohio', 'Colorado'], name='state'),\n",
    "                    columns=pd.Index(['one', 'two', 'three'],\n",
    "                    name='number'))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça uma operação de unpivoting (stack) com o dataframe data e guarde na variavel result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça uma operação de pivoting (unstack) com o dataframe result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
